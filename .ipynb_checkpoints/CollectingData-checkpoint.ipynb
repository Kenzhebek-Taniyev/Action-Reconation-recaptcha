{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cbfee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from extract import mediapipe_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd54d4",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f2a749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['climb', 'cry', 'drink', 'eat', 'fall', 'give', 'jump', 'kick',\n",
       "       'look', 'push', 'run', 'sit', 'sleep', 'wait', 'walk', 'wash'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'Dataset'\n",
    "path_action_types = 'types of actions'\n",
    "\n",
    "# Classes\n",
    "classes = np.array([clas[:-4] for clas in os.listdir(path_action_types)]) \n",
    "\n",
    "# Number of frames per video\n",
    "len_sequence = 30\n",
    "\n",
    "# Number of videos per action\n",
    "num_of_sequences = 50\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209455f",
   "metadata": {},
   "source": [
    "# Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab1dc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Directories for saving the Dataset\n",
    "for clas in classes:\n",
    "    for cut in range(num_of_sequences):\n",
    "        try:\n",
    "            os.makedirs('PATH' +'\\\\'+ clas +'\\\\'+ str(cut))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "# Collecting dataset\n",
    "# AKA: 54 min of pain and family members asking \"why u repeatedly touching your eye???\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "with holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as model:\n",
    "    for i, clas in enumerate(classes):\n",
    "        \n",
    "        tutorial_path = os.path.join(path_action_types, clas+'.png')  # Shows the tutorial image first for 2.5 sec\n",
    "        tutorial_image = cv2.imread(tutorial_path, cv2.IMREAD_COLOR)\n",
    "        tutorial_image = cv2.resize(tutorial_image, (450, 360))\n",
    "        h, w, _ = tutorial_image.shape\n",
    "\n",
    "        cv2.imshow('OpenCV Feed', tutorial_image)\n",
    "        cv2.waitKey(2500)\n",
    "\n",
    "        for cut in range(num_of_sequences):                        # For every frame:\n",
    "        \n",
    "            _, frame = cap.read()\n",
    "            image, _ = mediapipe_landmarks(frame, model)\n",
    "            \n",
    "            cv2.putText(image, 'Prepare: ', (100, 200),                              # 1.4 sec delay before starting to capture\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 4, cv2.LINE_AA) \n",
    "            cv2.putText(image, f'({i}) {clas}...', (40, 25),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "            cv2.waitKey(1400)\n",
    "            \n",
    "            for frame_num in range(len_sequence):\n",
    "                _, frame = cap.read()\n",
    "                image, landmarks = mediapipe_landmarks(frame, model)              # Get keypoints and draw landmarks\n",
    "                \n",
    "                tutorial_path = os.path.join(path_action_types, clas+'.png')      # Put tutorial image to right bottom\n",
    "                tutorial_image = cv2.imread(tutorial_path, cv2.IMREAD_COLOR)\n",
    "                tutorial_image = cv2.resize(tutorial_image, (150, 120))\n",
    "                h, w, _ = tutorial_image.shape\n",
    "                image[360:h+360, 490:w+490] = tutorial_image\n",
    "                             \n",
    "                cv2.putText(image, f'({i}) {clas}: {cut}', (40, 25),         # Print class and frame count (that is really painfull without them)\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                \n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                    \n",
    "                np.save(os.path.join(PATH, clas, str(cut), str(frame_num)), landmarks)  # Save the data\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):                                         # break if interrupted or 'q' pressing\n",
    "                    break\n",
    "\n",
    "    cap.release()            # Zuckerberg is watching\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450ec7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
